{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cdd109-11f7-423f-9240-bdde1bacac0f",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Pre-procesado de los datos - Detección de noticias falsas\n",
    "\n",
    "José Luis Aguilera Luzania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0b164-a700-4adf-a4f4-780f517075dc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "**¿Qué es la detección de *Fake News*?**\n",
    "La detección de noticias falsas (Fake News) es la tarea de evaluar la veracidad de las afirmaciones en las noticias. Este es un problema crítico en el Procesamiento del Lenguaje Natural (PLN) porque tanto en medios de noticias tradicionales como en medios digitales las Fake News generan un gran impacto social y político en cada individuo. Por ejemplo, la exposición a las Fake News puede generar actitudes de ineficacia, alienación y cinismo hacia ciertos candidatos políticos (Balmas, 2014).\n",
    "\n",
    "**Objetivo de la libreta**\n",
    "El objetivo de esta libreta es separar los datos que necesitamos de todo el conjunto de datos, limpiar los datos necesarios y estructurarlos para un análisis exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dcd3a-e0a0-4fcc-bc69-a6c7709eddc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "**Librerías**\n",
    "\n",
    "- Manipulación de datos:\n",
    "    - `pandas`: Librería para manipular los datos de forma tabular.\n",
    "    - `unicode`: Librería para eliminar acentos de las palabras.\n",
    "    - `re`: Librería para utilizar expresiones regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9086439b-9a97-4278-a569-6d430ddd92d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a92f-de36-465e-8fca-d9624251e99b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Leer los datos\n",
    "\n",
    "Los datos están divididos en los archivos `train.xlsx` y `development.xlsx`, con 80% para entrenamiento y 20% para pruebas respectivamente.\n",
    "\n",
    "Para cargar los conjuntos de datos se utilizará la librería `pandas` y su estructura `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecdef95-3ace-483f-a23c-e4dc10e0158c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_entrenamiento = pd.read_excel('Datos/train.xlsx')\n",
    "df_pruebas = pd.read_excel('Datos/development.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31eb8-e73f-4c10-a2d0-3aba3a3e4dbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Conjunto de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01c3fbe-3f19-4a14-9dbe-e475afd08305",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias, Columnas: (676, 7)\n",
      "Columnas: ['Id', 'Category', 'Topic', 'Source', 'Headline', 'Text', 'Link']\n",
      "Noticias verdaderas: 338\n",
      "Noticias falsas: 338\n"
     ]
    }
   ],
   "source": [
    "print(f'Noticias, Columnas: {df_entrenamiento.shape}')\n",
    "print(f'Columnas: {list(df_entrenamiento.columns)}')\n",
    "print('Noticias verdaderas: {}'.format(df_entrenamiento.groupby('Category').size()[0]))\n",
    "print('Noticias falsas: {}'    .format(df_entrenamiento.groupby('Category').size()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5b58d-9463-4c23-ad2d-4f7833d8ea49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Conjunto de pruebas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a005c9-cae8-422e-a840-17f5f3be440e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias, Columnas: (295, 7)\n",
      "Columnas: ['Id', 'Category', 'Topic', 'Source', 'Headline', 'Text', 'Link']\n",
      "Noticias verdaderas: 142\n",
      "Noticias falsas: 153\n"
     ]
    }
   ],
   "source": [
    "print(f'Noticias, Columnas: {df_pruebas.shape}')\n",
    "print(f'Columnas: {list(df_pruebas.columns)}')\n",
    "print('Noticias verdaderas: {}'.format(df_pruebas.groupby('Category').size()[0]))\n",
    "print('Noticias falsas: {}'    .format(df_pruebas.groupby('Category').size()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4e9ef-15fc-4e13-9dfc-b0b244ea0c03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ¿Por qué pre-procesar los datos?\n",
    "\n",
    "Durante el análisis de los datos en la libreta anterior <<1. Análisis de los datos>> se observó que varias fuentes se encontraban escritas de forma diferente, esto provoca un incremento en el número de fuentes diferentes que se obtienen y, por lo tanto, el número de fuentes obtenidas era mucho mayor al número de fuentes real, para solucionar este problema es necesario pre-procesar los datos.\n",
    "\n",
    "Con el propósito de evitar problemas futuros como el conteo incorrecto de las fuentes, se realizara una eliminación de datos innecesarios y una limpieza de los datos a utilizar.\n",
    "\n",
    "**¿Cuáles son los pasos a seguir?**\n",
    "\n",
    "1. Eliminar las columnas `Id` y `Link` de los conjuntos de datos.\n",
    "2. Procesar las columnas `Category`, `Topic`, `Source`, `Headline`, `Text` como se procesaron las fuentes en la libreta anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a30729-dc83-4da6-ad94-403968ca59ff",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Eliminar las columnas `Id` y `Link`\n",
    "\n",
    "Los datos de la columna:\n",
    "- `Id` son útiles para identificar cada una de las instancias de las noticias.\n",
    "- `Link` son útiles para leer el artículo original o comprobar si la noticia existe.\n",
    "en este caso, no son datos necesarios o útiles para el siguiente análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f231872e-21a6-41a7-9743-cee8c0ab5b63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Actualizar los dataframe.\n",
    "df_entrenamiento = df_entrenamiento.drop(columns=['Id', 'Link'])\n",
    "df_pruebas = df_pruebas.drop(columns=['Id', 'Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5525238a-a5bc-420d-822f-57d7f905520b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas entrenamiento: ['Category', 'Topic', 'Source', 'Headline', 'Text']\n",
      "Columnas pruebas: ['Category', 'Topic', 'Source', 'Headline', 'Text']\n"
     ]
    }
   ],
   "source": [
    "# Comprobar las columnas.\n",
    "print(f'Columnas entrenamiento: {list(df_entrenamiento.columns)}')\n",
    "print(f'Columnas pruebas: {list(df_pruebas.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e516417-de8d-4bf0-bc8d-4f1377b9b90a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Procesamiento de las columnas: `Category`, `Topic`, `Source`, `Headline`, `Text`\n",
    "\n",
    "Con el fin de agilizar el proceso de procesamiento, se definirán dos funciones: `procesar_texto` y `procesar_columnas`.\n",
    "\n",
    "- La función `procesar_textos` es la función `procesar_fuentes` de la libreta anterior, solo que renombrada para que se ajuste a su nuevo propósito.\n",
    "- La función `procesar_columnas` aplicará la función `procesar_textos` a las columnas especificadas de un `DataFrame`.\n",
    "\n",
    "Como recordatorio la función `procesar_textos` realiza lo siguiente:\n",
    "1. Convertir el texto en minúsculas.\n",
    "2. Eliminar acentos.\n",
    "3. Eliminar todo lo que no sea una palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eeb10fb-04e8-4071-b6aa-6f5dcc87997d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def procesar_texto(texto):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        texto: una cadena de texto.\n",
    "\n",
    "    Output:\n",
    "        texto: una cadena de texto formada solo por las palabras del texto original, sin acentos, caracteres especiales o espacios extra.\n",
    "    \"\"\"\n",
    "    # 1. Convertir el texto en minúsculas.\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # 2. Eliminar acentos.\n",
    "    texto = unidecode.unidecode(texto)\n",
    "    \n",
    "    # 3. Quedarnos solo con las palabras.\n",
    "    texto = re.findall(r'\\w+', texto)\n",
    "    texto = ' '.join(texto)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42a8547-f898-4047-bb10-080317bece5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def procesar_columnas(df, columnas, funcion_procesar):\n",
    "    \n",
    "    for col in columnas:\n",
    "        df[col] = df[col].apply(funcion_procesar)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa6503b-be1c-4472-be7a-68a996cf6020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de columnas a procesar.\n",
    "columnas_a_procesar = ['Category', 'Topic', 'Source', 'Headline', 'Text']\n",
    "\n",
    "# Procesamiento.\n",
    "df_entrenamiento = procesar_columnas(df_entrenamiento, columnas_a_procesar, procesar_texto)\n",
    "df_pruebas = procesar_columnas(df_pruebas, columnas_a_procesar, procesar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36e1ce-af9f-4f30-9650-d26c879709a3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Renombrar las columnas de los DataFrame.\n",
    "\n",
    "Las columnas se encuentran escritas en inglés, pero los datos como el texto en español, para evitar inconsistencias en el análisis exploratorio las columnas se traducirán al español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9b9055-1ddc-4144-b73c-098dbc430658",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columnas_dict = {\n",
    "    'Category': 'Categoria',\n",
    "    'Topic': 'Tema',\n",
    "    'Source': 'Fuente',\n",
    "    'Headline': 'Encabezado',\n",
    "    'Text': 'Texto'\n",
    "}\n",
    "\n",
    "df_entrenamiento.rename(columns=columnas_dict, inplace=True)\n",
    "df_pruebas.rename(columns=columnas_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Renombrar los temas\n",
    "Los temas también deberían estar en español.\n",
    "\n",
    "Como recordatorio los temas abarcados en las noticias son los siguientes:\n",
    "1. Ciencia.\n",
    "2. Deportes.\n",
    "3. Economía.\n",
    "4. Entretenimiento.\n",
    "5. Educación.\n",
    "6. Política.\n",
    "7. Salud.\n",
    "8. Seguridad.\n",
    "9. Sociedad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def renombrar_temas(df):\n",
    "    df.loc[df['Tema'] == 'economy'      , 'Tema'] = 'economía'\n",
    "    df.loc[df['Tema'] == 'education'    , 'Tema'] = 'educación'\n",
    "    df.loc[df['Tema'] == 'entertainment', 'Tema'] = 'entretenimiento'\n",
    "    df.loc[df['Tema'] == 'health'       , 'Tema'] = 'salud'\n",
    "    df.loc[df['Tema'] == 'politics'     , 'Tema'] = 'política'\n",
    "    df.loc[df['Tema'] == 'science'      , 'Tema'] = 'ciencia'\n",
    "    df.loc[df['Tema'] == 'security'     , 'Tema'] = 'seguridad'\n",
    "    df.loc[df['Tema'] == 'society'      , 'Tema'] = 'sociedad'\n",
    "    df.loc[df['Tema'] == 'sport'        , 'Tema'] = 'deportes'\n",
    "\n",
    "renombrar_temas(df_entrenamiento)\n",
    "renombrar_temas(df_pruebas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Renombrar las categorías\n",
    "Las categorías también serán traducidas al español."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def renombrar_categorias(df):\n",
    "    df.loc[df['Categoria'] == 'fake'      , 'Categoria'] = 'falsa'\n",
    "    df.loc[df['Categoria'] == 'true'      , 'Categoria'] = 'verdadera'\n",
    "\n",
    "renombrar_categorias(df_entrenamiento)\n",
    "renombrar_categorias(df_pruebas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "931496f1-7ed9-4e31-8d23-f3106ecbb067",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Guardar los DataFrame en archivos de texto.\n",
    "\n",
    "Ahora que los conjuntos se encuentran procesados y totalmente en español, para poder ser utilizados en otra libreta es necesario guardar los datos en archivos, se guardarán en archivos de extensión `.csv` llamados `datos_entrenamiento.csv` y `datos_pruebas.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fc7634-83da-4ca4-97e4-6dcd8bad5d47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_entrenamiento.to_csv('Datos/datos_entrenamiento.csv', index=False)\n",
    "df_pruebas.to_csv('Datos/datos_pruebas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}