{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cdd109-11f7-423f-9240-bdde1bacac0f",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Pre-procesado de los datos - Detección de noticias falsas\n",
    "\n",
    "José Luis Aguilera Luzania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0b164-a700-4adf-a4f4-780f517075dc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "**¿Qué es la detección de *Fake News*?**\n",
    "La detección de noticias falsas (Fake News) es la tarea de evaluar la veracidad de las afirmaciones en las noticias. Este es un problema crítico en el Procesamiento del Lenguaje Natural (PLN) porque tanto en medios de noticias tradicionales como en medios digitales las Fake News generan un gran impacto social y político en cada individuo. Por ejemplo, la exposición a las Fake News puede generar actitudes de ineficacia, alienación y cinismo hacia ciertos candidatos políticos (Balmas, 2014).\n",
    "\n",
    "**Objetivo de la libreta**\n",
    "El objetivo de esta libreta es separar los datos que necesitamos de todo el conjunto de datos, limpiar los datos necesarios y estructurarlos para un análisis exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dcd3a-e0a0-4fcc-bc69-a6c7709eddc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Librerías y los datos\n",
    "\n",
    "**Librerías**\n",
    "\n",
    "- Manipulación de datos:\n",
    "    - `pandas`: Librería para manipular los datos de forma tabular.\n",
    "    - `unicode`: Librería para eliminar acentos de las palabras.\n",
    "    - `re`: Librería para utilizar expresiones regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9086439b-9a97-4278-a569-6d430ddd92d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import procesar_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a92f-de36-465e-8fca-d9624251e99b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Leer los datos\n",
    "\n",
    "Los datos están divididos en los archivos `train.xlsx` y `development.xlsx`, con 80% para entrenamiento y 20% para pruebas respectivamente.\n",
    "\n",
    "Para cargar los conjuntos de datos se utilizará la librería `pandas` y su estructura `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ecdef95-3ace-483f-a23c-e4dc10e0158c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_entrenamiento = pd.read_excel('Datos/train.xlsx')\n",
    "df_pruebas = pd.read_excel('Datos/development.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unión de los conjuntos de datos\n",
    "\n",
    "Realizar las mismas operaciones sobre los dos conjuntos de datos y los mismos análisis puede ser contraproducente, un proceso tardado y tedioso, por lo tanto, se unirán los dos `DataFrame` en uno. Durante el proceso previo al entrenamiento los datos serán modificados y divididos de nuevo, pero eso será después del análisis exploratorio."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "      Id Category          Topic          Source  \\\n0      1     Fake      Education  El Ruinaversal   \n1      2     Fake      Education     Hay noticia   \n2      3     Fake      Education  El Ruinaversal   \n3      4     True      Education    EL UNIVERSAL   \n4      5     Fake      Education          Lamula   \n..   ...      ...            ...             ...   \n290  291     True  Entertainment        HUFFPOST   \n291  292     Fake  Entertainment  La voz popular   \n292  293     True  Entertainment       Billboard   \n293  294     True  Entertainment    EL UNIVERSAL   \n294  295     Fake  Entertainment       El Dizque   \n\n                                              Headline  \\\n0    RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...   \n1              La palabra \"haiga\", aceptada por la RAE   \n2    YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...   \n3    UNAM capacitará a maestros para aprobar prueba...   \n4    pretenden aprobar libros escolares con conteni...   \n..                                                 ...   \n290  Meryl Streep disfrutó unos premios Oscar tan m...   \n291  EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...   \n292  Ricardo Arjona lanza una serie documental por ...   \n293  Raúl Araiza sorprende a Andrea Legarreta con b...   \n294  Adal Ramones protagonizará el remake de El Cha...   \n\n                                                  Text  \\\n0    RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...   \n1    La palabra \"haiga\", aceptada por la RAE La Rea...   \n2    YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...   \n3    UNAM capacitará a maestros para aprobar prueba...   \n4    Alerta: pretenden aprobar libros escolares con...   \n..                                                 ...   \n290  Meryl Streep disfrutó unos premios Oscar tan m...   \n291  EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...   \n292  Ricardo Arjona lanza una serie documental por ...   \n293  Raúl Araiza sorprende a Andrea Legarreta con b...   \n294  Adal Ramones protagonizará el remake de El Cha...   \n\n                                                  Link  \n0    http://www.elruinaversal.com/2017/06/10/rae-in...  \n1    https://haynoticia.es/la-palabra-haiga-aceptad...  \n2    http://www.elruinaversal.com/2018/05/06/yordi-...  \n3    http://www.eluniversal.com.mx/articulo/nacion/...  \n4    https://redaccion.lamula.pe/2018/06/19/memoria...  \n..                                                 ...  \n290  https://www.huffingtonpost.com.mx/2018/03/06/m...  \n291  http://lavozpopular.com/plagio-lana-del-rey-ra...  \n292  http://www.billboard.com.ar/noticia/2980/ricar...  \n293  http://www.eluniversal.com.mx/espectaculos/rau...  \n294  https://www.eldizque.com/adal-ramones-protagon...  \n\n[971 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n      <th>Topic</th>\n      <th>Source</th>\n      <th>Headline</th>\n      <th>Text</th>\n      <th>Link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Fake</td>\n      <td>Education</td>\n      <td>El Ruinaversal</td>\n      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n      <td>http://www.elruinaversal.com/2017/06/10/rae-in...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Fake</td>\n      <td>Education</td>\n      <td>Hay noticia</td>\n      <td>La palabra \"haiga\", aceptada por la RAE</td>\n      <td>La palabra \"haiga\", aceptada por la RAE La Rea...</td>\n      <td>https://haynoticia.es/la-palabra-haiga-aceptad...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Fake</td>\n      <td>Education</td>\n      <td>El Ruinaversal</td>\n      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n      <td>http://www.elruinaversal.com/2018/05/06/yordi-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>True</td>\n      <td>Education</td>\n      <td>EL UNIVERSAL</td>\n      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n      <td>http://www.eluniversal.com.mx/articulo/nacion/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Fake</td>\n      <td>Education</td>\n      <td>Lamula</td>\n      <td>pretenden aprobar libros escolares con conteni...</td>\n      <td>Alerta: pretenden aprobar libros escolares con...</td>\n      <td>https://redaccion.lamula.pe/2018/06/19/memoria...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>291</td>\n      <td>True</td>\n      <td>Entertainment</td>\n      <td>HUFFPOST</td>\n      <td>Meryl Streep disfrutó unos premios Oscar tan m...</td>\n      <td>Meryl Streep disfrutó unos premios Oscar tan m...</td>\n      <td>https://www.huffingtonpost.com.mx/2018/03/06/m...</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>292</td>\n      <td>Fake</td>\n      <td>Entertainment</td>\n      <td>La voz popular</td>\n      <td>EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...</td>\n      <td>EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...</td>\n      <td>http://lavozpopular.com/plagio-lana-del-rey-ra...</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>293</td>\n      <td>True</td>\n      <td>Entertainment</td>\n      <td>Billboard</td>\n      <td>Ricardo Arjona lanza una serie documental por ...</td>\n      <td>Ricardo Arjona lanza una serie documental por ...</td>\n      <td>http://www.billboard.com.ar/noticia/2980/ricar...</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>294</td>\n      <td>True</td>\n      <td>Entertainment</td>\n      <td>EL UNIVERSAL</td>\n      <td>Raúl Araiza sorprende a Andrea Legarreta con b...</td>\n      <td>Raúl Araiza sorprende a Andrea Legarreta con b...</td>\n      <td>http://www.eluniversal.com.mx/espectaculos/rau...</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>295</td>\n      <td>Fake</td>\n      <td>Entertainment</td>\n      <td>El Dizque</td>\n      <td>Adal Ramones protagonizará el remake de El Cha...</td>\n      <td>Adal Ramones protagonizará el remake de El Cha...</td>\n      <td>https://www.eldizque.com/adal-ramones-protagon...</td>\n    </tr>\n  </tbody>\n</table>\n<p>971 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datos = pd.concat([df_entrenamiento, df_pruebas])\n",
    "df_datos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "49b31eb8-e73f-4c10-a2d0-3aba3a3e4dbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Información de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a01c3fbe-3f19-4a14-9dbe-e475afd08305",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias verdaderas: 480\n",
      "Noticias falsas: 491\n",
      "Todal de Noticias: 971\n",
      "Columnas: ['Id', 'Category', 'Topic', 'Source', 'Headline', 'Text', 'Link']\n"
     ]
    }
   ],
   "source": [
    "print('Noticias verdaderas: {}'.format(df_datos.groupby('Category').size()[0]))\n",
    "print('Noticias falsas: {}'    .format(df_datos.groupby('Category').size()[1]))\n",
    "print(f'Todal de Noticias: {df_datos.shape[0]}')\n",
    "print(f'Columnas: {list(df_datos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4e9ef-15fc-4e13-9dfc-b0b244ea0c03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ¿Por qué pre-procesar los datos?\n",
    "\n",
    "Durante el análisis de los datos en la libreta anterior <<1. Análisis de los datos>> se observó que varias fuentes se encontraban escritas de forma diferente, esto provoca un incremento en el número de fuentes diferentes que se obtienen y, por lo tanto, el número de fuentes obtenidas era mucho mayor al número de fuentes real, para solucionar este problema es necesario pre-procesar los datos.\n",
    "\n",
    "Con el propósito de evitar problemas futuros como el conteo incorrecto de las fuentes, se realizara una eliminación de datos innecesarios y una limpieza de los datos a utilizar.\n",
    "\n",
    "**¿Cuáles son los pasos a seguir?**\n",
    "\n",
    "1. Eliminar las columnas `Id` y `Link` de los conjuntos de datos.\n",
    "2. Procesar las columnas `Category`, `Topic`, `Source`, `Headline`, `Text` como se procesaron las fuentes en la libreta anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a30729-dc83-4da6-ad94-403968ca59ff",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Eliminar las columnas `Id` y `Link`\n",
    "\n",
    "Los datos de la columna:\n",
    "- `Id` son útiles para identificar cada una de las instancias de las noticias.\n",
    "- `Link` son útiles para leer el artículo original o comprobar si la noticia existe.\n",
    "\n",
    "en este caso, no son datos necesarios o útiles para el siguiente análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5525238a-a5bc-420d-822f-57d7f905520b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas: ['Category', 'Topic', 'Source', 'Headline', 'Text']\n"
     ]
    }
   ],
   "source": [
    "# Paso 1\n",
    "df_datos = df_entrenamiento.drop(columns=['Id', 'Link'])\n",
    "\n",
    "# Paso 2\n",
    "print(f'Columnas: {list(df_datos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e516417-de8d-4bf0-bc8d-4f1377b9b90a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Procesamiento de las columnas: `Category`, `Topic`, `Source`, `Headline`, `Text`\n",
    "\n",
    "Con el fin de agilizar el proceso de procesamiento, se definirán dos funciones: `procesar_texto` y `procesar_columnas`.\n",
    "\n",
    "- La función `procesar_textos` es la función `procesar_fuentes` de la libreta anterior, solo que renombrada para que se ajuste a su nuevo propósito.\n",
    "- La función `procesar_columnas` aplicará la función `procesar_textos` a las columnas especificadas de un `DataFrame`.\n",
    "\n",
    "Como recordatorio la función `procesar_textos` realiza lo siguiente:\n",
    "1. Convertir el texto en minúsculas.\n",
    "2. Eliminar acentos.\n",
    "3. Eliminar todo lo que no sea una palabra.\n",
    "\n",
    "La implementación de la función se encuentra en el archivo `utils.py` y su definición es la siguiente:\n",
    "```python\n",
    "def procesar_texto(texto):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        texto: una cadena de texto.\n",
    "\n",
    "    Output:\n",
    "        texto: una cadena de texto formada solo por las palabras del texto original, sin acentos, caracteres especiales o espacios extra.\n",
    "    \"\"\"\n",
    "    # 1. Convertir el texto en minúsculas.\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # 2. Eliminar acentos.\n",
    "    texto = unidecode.unidecode(texto)\n",
    "\n",
    "    # 3. Quedarnos solo con las palabras.\n",
    "    texto = re.findall(r'\\w+', texto)\n",
    "    texto = ' '.join(texto)\n",
    "\n",
    "    return texto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con el fin de procesar varias columnas a la vez, también se definio la función `procesar_columnas`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def procesar_columnas(df, columnas, funcion_procesar):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        df: DataFrame con las columnas a procesar.\n",
    "        columnas: lista de columnas a procesar.\n",
    "        funcion_procesar: función que se se utilizará para procesar.\n",
    "\n",
    "    Output: texto: una cadena de texto formada solo por las palabras del texto original, sin acentos, caracteres\n",
    "    especiales o espacios extra.\n",
    "    :type df: DataFrame\n",
    "    \"\"\"\n",
    "    for col in columnas:\n",
    "        df[col] = df[col].apply(funcion_procesar)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa6503b-be1c-4472-be7a-68a996cf6020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de columnas a procesar.\n",
    "columnas_a_procesar = ['Category', 'Topic', 'Source', 'Headline', 'Text']\n",
    "\n",
    "# Procesamiento.\n",
    "df_datos = procesar_columnas(df_datos, columnas_a_procesar, procesar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36e1ce-af9f-4f30-9650-d26c879709a3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Renombrar las columnas de los DataFrame.\n",
    "\n",
    "Las columnas se encuentran escritas en inglés, pero los datos como el texto en español, para evitar inconsistencias en el análisis exploratorio las columnas se traducirán al español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df9b9055-1ddc-4144-b73c-098dbc430658",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas: ['Categoria', 'Tema', 'Fuente', 'Encabezado', 'Texto']\n"
     ]
    }
   ],
   "source": [
    "columnas_dict = {\n",
    "    'Category': 'Categoria',\n",
    "    'Topic':    'Tema',\n",
    "    'Source':   'Fuente',\n",
    "    'Headline': 'Encabezado',\n",
    "    'Text':     'Texto'\n",
    "}\n",
    "\n",
    "# Renombrar las columnas.\n",
    "df_datos.rename(columns=columnas_dict, inplace=True)\n",
    "\n",
    "# Imprimir las columnas.\n",
    "print(f'Columnas: {list(df_datos.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Renombrar los temas\n",
    "Los temas también deberían estar en español.\n",
    "\n",
    "Como recordatorio los temas abarcados en las noticias son los siguientes:\n",
    "1. Ciencia.\n",
    "2. Deportes.\n",
    "3. Economía.\n",
    "4. Entretenimiento.\n",
    "5. Educación.\n",
    "6. Política.\n",
    "7. Salud.\n",
    "8. Seguridad.\n",
    "9. Sociedad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def renombrar_temas(df):\n",
    "    df.loc[df['Tema'] == 'economy'      , 'Tema'] = 'economía'\n",
    "    df.loc[df['Tema'] == 'education'    , 'Tema'] = 'educación'\n",
    "    df.loc[df['Tema'] == 'entertainment', 'Tema'] = 'entretenimiento'\n",
    "    df.loc[df['Tema'] == 'health'       , 'Tema'] = 'salud'\n",
    "    df.loc[df['Tema'] == 'politics'     , 'Tema'] = 'política'\n",
    "    df.loc[df['Tema'] == 'science'      , 'Tema'] = 'ciencia'\n",
    "    df.loc[df['Tema'] == 'security'     , 'Tema'] = 'seguridad'\n",
    "    df.loc[df['Tema'] == 'society'      , 'Tema'] = 'sociedad'\n",
    "    df.loc[df['Tema'] == 'sport'        , 'Tema'] = 'deportes'\n",
    "\n",
    "renombrar_temas(df_datos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Renombrar las categorías\n",
    "Las categorías también serán traducidas al español."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def renombrar_categorias(df):\n",
    "    df.loc[df['Categoria'] == 'fake', 'Categoria'] = 'falsa'\n",
    "    df.loc[df['Categoria'] == 'true', 'Categoria'] = 'verdadera'\n",
    "\n",
    "renombrar_categorias(df_datos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datos procesados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   Categoria       Tema          Fuente  \\\n0      falsa  educación  el ruinaversal   \n1      falsa  educación     hay noticia   \n2      falsa  educación  el ruinaversal   \n3  verdadera  educación    el universal   \n4      falsa  educación          lamula   \n\n                                          Encabezado  \\\n0  rae incluira la palabra lady en el diccionario...   \n1               la palabra haiga aceptada por la rae   \n2  yordi rosado escribira y disenara los nuevos l...   \n3  unam capacitara a maestros para aprobar prueba...   \n4  pretenden aprobar libros escolares con conteni...   \n\n                                               Texto  \n0  rae incluira la palabra lady en el diccionario...  \n1  la palabra haiga aceptada por la rae la real a...  \n2  yordi rosado escribira y disenara los nuevos l...  \n3  unam capacitara a maestros para aprobar prueba...  \n4  alerta pretenden aprobar libros escolares con ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Categoria</th>\n      <th>Tema</th>\n      <th>Fuente</th>\n      <th>Encabezado</th>\n      <th>Texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>falsa</td>\n      <td>educación</td>\n      <td>el ruinaversal</td>\n      <td>rae incluira la palabra lady en el diccionario...</td>\n      <td>rae incluira la palabra lady en el diccionario...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>falsa</td>\n      <td>educación</td>\n      <td>hay noticia</td>\n      <td>la palabra haiga aceptada por la rae</td>\n      <td>la palabra haiga aceptada por la rae la real a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>falsa</td>\n      <td>educación</td>\n      <td>el ruinaversal</td>\n      <td>yordi rosado escribira y disenara los nuevos l...</td>\n      <td>yordi rosado escribira y disenara los nuevos l...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>verdadera</td>\n      <td>educación</td>\n      <td>el universal</td>\n      <td>unam capacitara a maestros para aprobar prueba...</td>\n      <td>unam capacitara a maestros para aprobar prueba...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>falsa</td>\n      <td>educación</td>\n      <td>lamula</td>\n      <td>pretenden aprobar libros escolares con conteni...</td>\n      <td>alerta pretenden aprobar libros escolares con ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datos.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "931496f1-7ed9-4e31-8d23-f3106ecbb067",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Guardar los DataFrame en archivos de texto.\n",
    "\n",
    "Ahora los datos se encuentran procesados y totalmente en español, es necesario guardarlos en un archivo para poder utilizarlo en las libretas posteriores. Los datos se guardarán en el archivo con extensión `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67fc7634-83da-4ca4-97e4-6dcd8bad5d47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_datos.to_csv('Datos/datos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}