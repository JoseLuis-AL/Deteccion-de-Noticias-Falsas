{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cdd109-11f7-423f-9240-bdde1bacac0f",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Preprocesado de los datos - Detección de *Fake News*\n",
    "\n",
    "José Luis Aguilera Luzania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0b164-a700-4adf-a4f4-780f517075dc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "### ¿Qué es la detección de *Fake News*?\n",
    "- Es la tarea de evaluar la veracidad de las afirmaciones en las noticias.\n",
    "- Es un problema crítico en Procesamiento del Lenguaje Natural porque tanto en medios de noticias tradicionales como en medios digitales las Fake News generan un gran impacto social y político en cada individuo.\n",
    "- La exposición a las Fake News puede generar actitudes de ineficacia, alienación y cinismo hacia ciertos candidatos políticos (Balmas, 2014).\n",
    "\n",
    "### Objetivo de la libreta\n",
    "El objetivo de esta libreta es separar los datos que necesitamos de todo el conjunto de datos, limpiar los datos necesarios y estructurarlos para un análisis exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dcd3a-e0a0-4fcc-bc69-a6c7709eddc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "### Librerías\n",
    "\n",
    "- Manipulación de datos:\n",
    "    - `pandas`: Librería para manipular los datos de forma tabular.\n",
    "    - `matplotlib`: Librería para graficar.\n",
    "    - `openpyxl`: Librería para leer archivos de hoja de cálculo en pandas.\n",
    "    - `cmd`: Librería para controlar el formato de impresión en la consola.\n",
    "    - `unicode`: Librería para eliminar acentos de las palabras.\n",
    "    - `re`: Librería para utilizar expresiones regulares.\n",
    "    \n",
    "- Procesamiento del lenguaje natural:\n",
    "    - `nltk`: Librería para utilizar técnicas de procesameinto del lenguaje natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9086439b-9a97-4278-a569-6d430ddd92d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import cmd\n",
    "import unidecode\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded74cfe-83f3-4696-9eec-53d5765b90d9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Datos adicionales para la librería `nltk`\n",
    "- `punkt`: Necesario para utilizar el tokenizador de los textos.\n",
    "- `stopwords`: Palabras comunes que no añaden información, como: el, la, los, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9769787-1786-405d-825f-57bc0c91afa9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JoseLuis_AL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JoseLuis_AL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar los datos necesarios.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a92f-de36-465e-8fca-d9624251e99b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Leer los datos\n",
    "\n",
    "Los datos estan divididos en los archivos `train.xlsx` y `development.xlsx`, con 80% para entrenamiento y 20% para pruebas respectivamente.\n",
    "\n",
    "Para cargar los conjuntos de datos se utilizará la librería `pandas` y su estructura `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecdef95-3ace-483f-a23c-e4dc10e0158c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_entrenamiento = pd.read_excel('Datos/train.xlsx')\n",
    "df_pruebas = pd.read_excel('Datos/development.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31eb8-e73f-4c10-a2d0-3aba3a3e4dbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01c3fbe-3f19-4a14-9dbe-e475afd08305",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias, Columnas: (676, 7)\n",
      "Columnas: ['Id', 'Category', 'Topic', 'Source', 'Headline', 'Text', 'Link']\n",
      "Noticias verdaderas: 338\n",
      "Noticias falsas: 338\n"
     ]
    }
   ],
   "source": [
    "print(f'Noticias, Columnas: {df_entrenamiento.shape}')\n",
    "print(f'Columnas: {list(df_entrenamiento.columns)}')\n",
    "print('Noticias verdaderas: {}'.format(df_entrenamiento.groupby('Category').size()[0]))\n",
    "print('Noticias falsas: {}'    .format(df_entrenamiento.groupby('Category').size()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5b58d-9463-4c23-ad2d-4f7833d8ea49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a005c9-cae8-422e-a840-17f5f3be440e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias, Columnas: (295, 7)\n",
      "Columnas: ['Id', 'Category', 'Topic', 'Source', 'Headline', 'Text', 'Link']\n",
      "Noticias verdaderas: 142\n",
      "Noticias falsas: 153\n"
     ]
    }
   ],
   "source": [
    "print(f'Noticias, Columnas: {df_pruebas.shape}')\n",
    "print(f'Columnas: {list(df_pruebas.columns)}')\n",
    "print('Noticias verdaderas: {}'.format(df_pruebas.groupby('Category').size()[0]))\n",
    "print('Noticias falsas: {}'    .format(df_pruebas.groupby('Category').size()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4e9ef-15fc-4e13-9dfc-b0b244ea0c03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ¿Porqué limpiar los datos?\n",
    "\n",
    "Como se observo durante el análisis de los datos en la libreta 1, varias fuentes se econtraban escritas de manera incorrecta de tal forma que el número de fuentes encontradas en un inicio era mayor al número de fuentes real.  \n",
    "\n",
    "En esta libreta se impedirán problemas futuros al extraer los datos necesarios y limpiarlos.  \n",
    "\n",
    "El proceso para obtener los datos que necesitamos y como queremos es el siguiente:\n",
    "\n",
    "1. Eliminar las columna `Link`.\n",
    "2. Procesar las fuentes (`Source`).\n",
    "3. Procesar los encabezados (`Headline`).\n",
    "4. Procesar el texto (`Text`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a30729-dc83-4da6-ad94-403968ca59ff",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Eliminar las columnas `Id` y `Link`\n",
    "\n",
    "La columna `Link` es útil para leer el articulo de donde se obtuvo la noticia, pero al momento de realizar un análisis exploratorio o procesar el texto para utilizarlo en un algoritmo de clasificación no es muy útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f231872e-21a6-41a7-9743-cee8c0ab5b63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Columnas a eliminar.\n",
    "columnas = ['Id', 'Link']\n",
    "\n",
    "# Actualizar los dataframe.\n",
    "df_entrenamiento = df_entrenamiento.drop(columns=['Id', 'Link'])\n",
    "df_pruebas = df_pruebas.drop(columns=['Id', 'Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5525238a-a5bc-420d-822f-57d7f905520b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas entrenamiento: ['Category', 'Topic', 'Source', 'Headline', 'Text']\n",
      "Columnas pruebas: ['Category', 'Topic', 'Source', 'Headline', 'Text']\n"
     ]
    }
   ],
   "source": [
    "# Comprobar las columnas.\n",
    "print(f'Columnas entrenamiento: {list(df_entrenamiento.columns)}')\n",
    "print(f'Columnas pruebas: {list(df_pruebas.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e516417-de8d-4bf0-bc8d-4f1377b9b90a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Procesar textos\n",
    "\n",
    "Los textos de las columnas deben ser procesados para evitar problemas como el de las fuentes duplicadas por tener faltas de ortografía. \n",
    "\n",
    "Para procesar los textos se utilizará la misma función que se utilizo en la libreta 1 que ahora se llamará `procesar_textos` y consta de las siguientes reglas:\n",
    "\n",
    "1. Convertir todas las palabras en minúsculas.\n",
    "2. Eliminar acentos.\n",
    "3. Eliminar todo excepto las palabras.\n",
    "\n",
    "También se usará una función auxiliar llamada `procesar_textos_df` para procesar solo los datos de las columnas especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eeb10fb-04e8-4071-b6aa-6f5dcc87997d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def procesar_texto(texto):\n",
    "    '''\n",
    "    Input: \n",
    "        texto: una cadena de texto.\n",
    "        \n",
    "    Output:\n",
    "        texto: una cadena de texto formada solo por las palabras del texto original, sin acentos, caracteres especiales o espacios extra.\n",
    "    '''\n",
    "    # 1. Convertir el texto en minúsculas.\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # 2. Eliminar acentos.\n",
    "    texto = unidecode.unidecode(texto)\n",
    "    \n",
    "    # 3. Quedarnos solo con las palabras.\n",
    "    texto = re.findall(r'\\w+', texto)\n",
    "    texto = ' '.join(texto)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a42a8547-f898-4047-bb10-080317bece5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def procesar_textos_df(df, columnas, funcion_procesar):\n",
    "    \n",
    "    for col in columnas:\n",
    "        df[col] = df[col].apply(funcion_procesar)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ef80a-a3cd-4b9a-8d32-2283049277fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aplicamos la función a los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa6503b-be1c-4472-be7a-68a996cf6020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de columnas a procesar.\n",
    "columnas_a_procesar = ['Category', 'Topic', 'Source', 'Headline', 'Text']\n",
    "\n",
    "# Procesamiento.\n",
    "df_entrenamiento = procesar_textos_df(df_entrenamiento, columnas_a_procesar, procesar_texto)\n",
    "df_pruebas = procesar_textos_df(df_pruebas, columnas_a_procesar, procesar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36e1ce-af9f-4f30-9650-d26c879709a3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Renombrar las columnas de los DataFrame.\n",
    "\n",
    "Las columnas se encuentran escritas en inglés pero los datos como el texto en español, para evitar inconsistencias en el análisis exploratorio las columnas se traducirán al español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df9b9055-1ddc-4144-b73c-098dbc430658",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columnas_dict = {\n",
    "    'Category': 'Categoria',\n",
    "    'Topic': 'Tema',\n",
    "    'Source': 'Fuente',\n",
    "    'Headline': 'Encabezado',\n",
    "    'Text': 'Texto'\n",
    "}\n",
    "\n",
    "df_entrenamiento.rename(columns=columnas_dict, inplace=True)\n",
    "df_pruebas.rename(columns=columnas_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931496f1-7ed9-4e31-8d23-f3106ecbb067",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Guardar los DataFrame en archivos de texto.\n",
    "\n",
    "Para utilizar los conjuntos de datos `df_entrenamiento` y `df_pruebas`, se guardarán en archivos de extensión `.csv` llamados `datos_entrenamiento.csv` y `datos_pruebas.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fc7634-83da-4ca4-97e4-6dcd8bad5d47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_entrenamiento.to_csv('Datos/datos_entrenamiento.csv', index=False)\n",
    "df_pruebas.to_csv('Datos/datos_pruebas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09cd15a8-3269-4d07-9853-1dc53661356f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}